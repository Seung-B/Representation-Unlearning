2024-04-21 16:40:26,702 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 8, 'num_workers': 8, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-04-21 16:40:38,221 CLIP_COCO_TRAIN INFO: ***** Running training *****
2024-04-21 16:40:38,221 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2024-04-21 16:40:38,222 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2024-04-21 16:40:38,222 CLIP_COCO_TRAIN INFO:   Number of GPUs = 8
2024-04-21 16:40:38,222 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2024-04-21 16:40:38,222 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 512
2024-04-21 16:40:38,222 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2024-04-21 16:40:38,222 CLIP_COCO_TRAIN INFO:   Total optimization steps = 8120
2024-04-21 16:40:38,222 CLIP_COCO_TRAIN INFO:   warmup steps = 1624
2024-04-21 16:56:32,425 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 8, 'num_workers': 8, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-04-21 16:56:45,069 CLIP_COCO_TRAIN INFO: ***** Running training *****
2024-04-21 16:56:45,070 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2024-04-21 16:56:45,070 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2024-04-21 16:56:45,070 CLIP_COCO_TRAIN INFO:   Number of GPUs = 8
2024-04-21 16:56:45,070 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2024-04-21 16:56:45,071 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 512
2024-04-21 16:56:45,071 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2024-04-21 16:56:45,071 CLIP_COCO_TRAIN INFO:   Total optimization steps = 8120
2024-04-21 16:56:45,071 CLIP_COCO_TRAIN INFO:   warmup steps = 1624
2024-04-21 17:01:29,513 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 50, lr: 0.000015, loss: 6.0557 (6.2038)
2024-04-21 17:05:01,806 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 100, lr: 0.000031, loss: 5.6615 (6.0176)
2024-04-21 17:08:31,174 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 150, lr: 0.000046, loss: 5.3025 (5.8239)
2024-04-21 17:12:09,037 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 200, lr: 0.000062, loss: 4.9283 (5.6355)
2024-04-21 17:16:03,892 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 250, lr: 0.000077, loss: 4.7949 (5.4603)
2024-04-21 17:19:26,847 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 300, lr: 0.000092, loss: 4.4609 (5.3104)
2024-04-21 17:22:53,510 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 350, lr: 0.000108, loss: 4.2494 (5.1837)
2024-04-21 17:26:16,171 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 400, lr: 0.000123, loss: 4.1889 (5.0678)
2024-04-21 17:30:08,309 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 450, lr: 0.000139, loss: 4.0484 (4.9665)
2024-04-21 17:33:31,207 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 500, lr: 0.000154, loss: 3.9197 (4.8710)
2024-04-21 17:36:55,526 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 550, lr: 0.000169, loss: 3.7788 (4.7817)
2024-04-21 17:40:20,715 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 600, lr: 0.000185, loss: 3.8443 (4.7016)
2024-04-21 17:44:07,189 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 650, lr: 0.000200, loss: 3.6851 (4.6296)
2024-04-21 17:47:36,957 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 700, lr: 0.000216, loss: 3.9296 (4.5619)
2024-04-21 17:50:50,372 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 750, lr: 0.000231, loss: 3.7134 (4.5012)
2024-04-21 17:54:16,513 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 800, lr: 0.000246, loss: 3.4209 (4.4400)
2024-04-21 17:57:57,676 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 850, lr: 0.000262, loss: 3.5558 (4.3839)
2024-04-21 18:01:29,113 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 900, lr: 0.000277, loss: 3.5145 (4.3321)
2024-04-21 18:04:45,045 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 950, lr: 0.000292, loss: 3.3344 (4.2864)
2024-04-21 18:08:05,383 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 1000, lr: 0.000308, loss: 3.1951 (4.2375)
2024-04-21 18:08:26,518 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_4_1000.pt
2024-04-21 18:11:59,090 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 1050, lr: 0.000323, loss: 3.3079 (4.1908)
2024-04-21 18:15:23,375 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 1100, lr: 0.000339, loss: 3.2473 (4.1470)
2024-04-21 18:18:44,053 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 1150, lr: 0.000354, loss: 3.1795 (4.1053)
2024-04-21 18:21:52,779 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 1200, lr: 0.000369, loss: 3.1939 (4.0659)
2024-04-21 18:25:39,006 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 1250, lr: 0.000385, loss: 3.0550 (4.0259)
2024-04-21 18:29:03,571 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 1300, lr: 0.000400, loss: 3.0187 (3.9881)
2024-04-21 18:32:27,415 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 1350, lr: 0.000416, loss: 3.0198 (3.9518)
2024-04-21 18:35:55,120 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 1400, lr: 0.000431, loss: 3.2085 (3.9184)
2024-04-21 18:39:18,099 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 1450, lr: 0.000446, loss: 2.9252 (3.8868)
2024-04-21 18:42:44,416 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 1500, lr: 0.000462, loss: 2.8521 (3.8526)
2024-04-21 18:46:06,569 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 1550, lr: 0.000477, loss: 2.8310 (3.8211)
2024-04-21 18:49:32,972 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 1600, lr: 0.000493, loss: 2.8899 (3.7908)
2024-04-21 18:53:09,759 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 1650, lr: 0.000500, loss: 2.8280 (3.7629)
2024-04-21 18:56:25,356 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 1700, lr: 0.000500, loss: 2.7986 (3.7331)
2024-04-21 18:59:48,156 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 1750, lr: 0.000500, loss: 2.8107 (3.7041)
2024-04-21 19:03:16,050 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 1800, lr: 0.000499, loss: 2.6375 (3.6751)
2024-04-21 19:06:54,215 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 1850, lr: 0.000499, loss: 2.7637 (3.6472)
2024-04-21 19:09:58,913 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 1900, lr: 0.000498, loss: 2.5577 (3.6204)
2024-04-21 19:13:20,303 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 1950, lr: 0.000497, loss: 2.3847 (3.5920)
2024-04-21 19:16:43,213 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 2000, lr: 0.000496, loss: 2.4940 (3.5639)
2024-04-21 19:16:53,802 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_8_2000.pt
2024-04-21 19:20:36,540 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 2050, lr: 0.000495, loss: 2.4406 (3.5370)
2024-04-21 19:23:57,186 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 2100, lr: 0.000493, loss: 2.6355 (3.5117)
2024-04-21 19:27:02,667 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 2150, lr: 0.000492, loss: 2.2439 (3.4861)
2024-04-21 19:30:28,973 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 2200, lr: 0.000490, loss: 2.3173 (3.4593)
2024-04-21 19:34:13,786 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 2250, lr: 0.000489, loss: 2.2379 (3.4334)
2024-04-21 19:37:37,148 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 2300, lr: 0.000487, loss: 2.2501 (3.4081)
2024-04-21 19:40:54,460 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 2350, lr: 0.000485, loss: 2.1307 (3.3818)
2024-04-21 19:44:12,211 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 2400, lr: 0.000483, loss: 2.0291 (3.3552)
2024-04-21 19:47:53,980 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 2450, lr: 0.000480, loss: 2.2511 (3.3299)
2024-04-21 19:51:20,877 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 2500, lr: 0.000478, loss: 2.0680 (3.3060)
2024-04-21 19:54:35,843 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 2550, lr: 0.000475, loss: 2.0564 (3.2833)
2024-04-21 19:57:53,198 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 2600, lr: 0.000473, loss: 1.9594 (3.2612)
2024-04-21 20:01:41,925 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 2650, lr: 0.000470, loss: 1.9678 (3.2374)
2024-04-21 20:05:08,935 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 2700, lr: 0.000467, loss: 2.0455 (3.2138)
2024-04-21 20:08:31,235 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 2750, lr: 0.000464, loss: 1.9349 (3.1916)
2024-04-21 20:11:47,473 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 2800, lr: 0.000461, loss: 1.8518 (3.1686)
2024-04-21 20:15:12,944 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 2850, lr: 0.000457, loss: 1.8609 (3.1448)
2024-04-21 20:18:36,739 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 2900, lr: 0.000454, loss: 1.8228 (3.1221)
2024-04-21 20:22:03,110 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 2950, lr: 0.000450, loss: 1.8664 (3.1007)
2024-04-21 20:25:27,896 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 3000, lr: 0.000447, loss: 1.8293 (3.0799)
2024-04-21 20:25:50,896 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_12_3000.pt
2024-04-21 20:29:07,257 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 3050, lr: 0.000443, loss: 1.8584 (3.0600)
2024-04-21 20:32:26,865 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 3100, lr: 0.000439, loss: 1.6792 (3.0387)
2024-04-21 20:35:52,138 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 3150, lr: 0.000435, loss: 1.6417 (3.0176)
2024-04-21 20:39:16,976 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 3200, lr: 0.000431, loss: 1.7224 (2.9977)
2024-04-21 20:43:02,140 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 3250, lr: 0.000427, loss: 1.9377 (2.9783)
2024-04-21 20:45:48,087 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 3300, lr: 0.000422, loss: 1.6432 (2.9613)
2024-04-21 20:49:07,387 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 3350, lr: 0.000418, loss: 1.6202 (2.9419)
2024-04-21 20:52:34,685 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 3400, lr: 0.000413, loss: 1.5717 (2.9227)
2024-04-21 20:56:22,155 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 3450, lr: 0.000409, loss: 1.6339 (2.9041)
2024-04-21 20:59:31,393 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 3500, lr: 0.000404, loss: 1.4981 (2.8846)
2024-04-21 21:02:31,839 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 3550, lr: 0.000399, loss: 1.4182 (2.8646)
2024-04-21 21:05:59,155 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 3600, lr: 0.000394, loss: 1.4774 (2.8454)
2024-04-21 21:09:47,501 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 3650, lr: 0.000389, loss: 1.4711 (2.8268)
2024-04-21 21:13:14,514 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 3700, lr: 0.000384, loss: 1.5665 (2.8090)
2024-04-21 21:16:18,326 CLIP_COCO_TRAIN INFO: Epoch: 16, global_step: 3750, lr: 0.000379, loss: 1.2913 (2.7910)
2024-04-21 21:19:32,345 CLIP_COCO_TRAIN INFO: Epoch: 16, global_step: 3800, lr: 0.000374, loss: 1.2635 (2.7724)
2024-04-21 21:23:19,855 CLIP_COCO_TRAIN INFO: Epoch: 16, global_step: 3850, lr: 0.000369, loss: 1.3460 (2.7544)
2024-04-21 21:26:47,153 CLIP_COCO_TRAIN INFO: Epoch: 16, global_step: 3900, lr: 0.000363, loss: 1.3668 (2.7370)
2024-04-21 21:30:10,946 CLIP_COCO_TRAIN INFO: Epoch: 17, global_step: 3950, lr: 0.000358, loss: 1.3611 (2.7195)
2024-04-21 21:32:57,477 CLIP_COCO_TRAIN INFO: Epoch: 17, global_step: 4000, lr: 0.000352, loss: 1.2692 (2.7015)
2024-04-21 21:33:11,685 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_17_4000.pt
2024-04-21 21:36:47,925 CLIP_COCO_TRAIN INFO: Epoch: 17, global_step: 4050, lr: 0.000347, loss: 1.2740 (2.6837)
2024-04-21 21:40:13,264 CLIP_COCO_TRAIN INFO: Epoch: 17, global_step: 4100, lr: 0.000341, loss: 1.3113 (2.6667)
2024-04-21 21:43:39,069 CLIP_COCO_TRAIN INFO: Epoch: 17, global_step: 4150, lr: 0.000336, loss: 1.2958 (2.6502)
2024-04-21 21:46:38,828 CLIP_COCO_TRAIN INFO: Epoch: 18, global_step: 4200, lr: 0.000330, loss: 1.3999 (2.6347)
2024-04-21 21:49:53,941 CLIP_COCO_TRAIN INFO: Epoch: 18, global_step: 4250, lr: 0.000324, loss: 1.2426 (2.6184)
2024-04-21 21:53:21,417 CLIP_COCO_TRAIN INFO: Epoch: 18, global_step: 4300, lr: 0.000318, loss: 1.1868 (2.6020)
2024-04-21 21:56:48,607 CLIP_COCO_TRAIN INFO: Epoch: 18, global_step: 4350, lr: 0.000312, loss: 1.1400 (2.5858)
2024-04-21 22:00:15,546 CLIP_COCO_TRAIN INFO: Epoch: 18, global_step: 4400, lr: 0.000307, loss: 1.2708 (2.5702)
2024-04-21 22:03:29,509 CLIP_COCO_TRAIN INFO: Epoch: 19, global_step: 4450, lr: 0.000301, loss: 1.1057 (2.5545)
2024-04-21 22:06:46,611 CLIP_COCO_TRAIN INFO: Epoch: 19, global_step: 4500, lr: 0.000295, loss: 1.1294 (2.5381)
2024-04-21 22:10:11,231 CLIP_COCO_TRAIN INFO: Epoch: 19, global_step: 4550, lr: 0.000289, loss: 1.0715 (2.5224)
2024-04-21 22:13:38,267 CLIP_COCO_TRAIN INFO: Epoch: 19, global_step: 4600, lr: 0.000283, loss: 1.1346 (2.5069)
2024-04-21 22:17:19,801 CLIP_COCO_TRAIN INFO: Epoch: 20, global_step: 4650, lr: 0.000277, loss: 0.9503 (2.4914)
2024-04-21 22:20:02,407 CLIP_COCO_TRAIN INFO: Epoch: 20, global_step: 4700, lr: 0.000271, loss: 1.0340 (2.4757)
2024-04-21 22:23:13,657 CLIP_COCO_TRAIN INFO: Epoch: 20, global_step: 4750, lr: 0.000265, loss: 0.9255 (2.4601)
2024-04-21 22:26:38,250 CLIP_COCO_TRAIN INFO: Epoch: 20, global_step: 4800, lr: 0.000259, loss: 0.9698 (2.4452)
2024-04-21 22:30:22,785 CLIP_COCO_TRAIN INFO: Epoch: 20, global_step: 4850, lr: 0.000253, loss: 1.1180 (2.4304)
2024-04-21 22:33:25,266 CLIP_COCO_TRAIN INFO: Epoch: 21, global_step: 4900, lr: 0.000247, loss: 1.0222 (2.4155)
2024-04-21 22:36:21,232 CLIP_COCO_TRAIN INFO: Epoch: 21, global_step: 4950, lr: 0.000241, loss: 0.9459 (2.4005)
2024-04-21 22:39:48,559 CLIP_COCO_TRAIN INFO: Epoch: 21, global_step: 5000, lr: 0.000235, loss: 0.9496 (2.3858)
2024-04-21 22:40:07,719 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_21_5000.pt
2024-04-21 22:43:43,881 CLIP_COCO_TRAIN INFO: Epoch: 21, global_step: 5050, lr: 0.000229, loss: 0.8858 (2.3715)
2024-04-21 22:47:04,750 CLIP_COCO_TRAIN INFO: Epoch: 21, global_step: 5100, lr: 0.000222, loss: 0.9033 (2.3575)
2024-04-21 22:49:45,900 CLIP_COCO_TRAIN INFO: Epoch: 22, global_step: 5150, lr: 0.000216, loss: 0.8641 (2.3430)
2024-04-21 22:52:59,088 CLIP_COCO_TRAIN INFO: Epoch: 22, global_step: 5200, lr: 0.000211, loss: 0.8460 (2.3285)
2024-04-21 22:56:47,286 CLIP_COCO_TRAIN INFO: Epoch: 22, global_step: 5250, lr: 0.000205, loss: 0.7954 (2.3144)
2024-04-21 23:00:15,428 CLIP_COCO_TRAIN INFO: Epoch: 22, global_step: 5300, lr: 0.000199, loss: 0.9428 (2.3007)
2024-04-21 23:03:26,369 CLIP_COCO_TRAIN INFO: Epoch: 23, global_step: 5350, lr: 0.000193, loss: 0.8926 (2.2871)
2024-04-21 23:06:27,943 CLIP_COCO_TRAIN INFO: Epoch: 23, global_step: 5400, lr: 0.000187, loss: 0.7743 (2.2732)
2024-04-21 23:10:09,233 CLIP_COCO_TRAIN INFO: Epoch: 23, global_step: 5450, lr: 0.000181, loss: 0.8754 (2.2597)
2024-04-21 23:13:34,712 CLIP_COCO_TRAIN INFO: Epoch: 23, global_step: 5500, lr: 0.000175, loss: 0.8351 (2.2464)
2024-04-21 23:17:01,761 CLIP_COCO_TRAIN INFO: Epoch: 23, global_step: 5550, lr: 0.000169, loss: 0.8590 (2.2333)
2024-04-21 23:19:58,535 CLIP_COCO_TRAIN INFO: Epoch: 24, global_step: 5600, lr: 0.000164, loss: 0.7759 (2.2202)
2024-04-21 23:23:23,684 CLIP_COCO_TRAIN INFO: Epoch: 24, global_step: 5650, lr: 0.000158, loss: 0.6641 (2.2070)
2024-04-21 23:26:48,731 CLIP_COCO_TRAIN INFO: Epoch: 24, global_step: 5700, lr: 0.000153, loss: 0.7153 (2.1941)
2024-04-21 23:30:19,300 CLIP_COCO_TRAIN INFO: Epoch: 24, global_step: 5750, lr: 0.000147, loss: 0.7634 (2.1812)
2024-04-21 23:33:41,708 CLIP_COCO_TRAIN INFO: Epoch: 24, global_step: 5800, lr: 0.000142, loss: 0.0619 (2.1687)
2024-04-21 23:36:54,779 CLIP_COCO_TRAIN INFO: Epoch: 25, global_step: 5850, lr: 0.000136, loss: 0.6311 (2.1559)
2024-04-21 23:40:08,729 CLIP_COCO_TRAIN INFO: Epoch: 25, global_step: 5900, lr: 0.000131, loss: 0.7307 (2.1434)
2024-04-21 23:43:32,247 CLIP_COCO_TRAIN INFO: Epoch: 25, global_step: 5950, lr: 0.000125, loss: 0.6500 (2.1309)
2024-04-21 23:46:54,807 CLIP_COCO_TRAIN INFO: Epoch: 25, global_step: 6000, lr: 0.000120, loss: 0.6357 (2.1187)
2024-04-21 23:47:14,591 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_25_6000.pt
2024-04-21 23:50:29,583 CLIP_COCO_TRAIN INFO: Epoch: 26, global_step: 6050, lr: 0.000115, loss: 0.7719 (2.1066)
2024-04-21 23:53:16,562 CLIP_COCO_TRAIN INFO: Epoch: 26, global_step: 6100, lr: 0.000110, loss: 0.6376 (2.0946)
2024-04-21 23:56:36,522 CLIP_COCO_TRAIN INFO: Epoch: 26, global_step: 6150, lr: 0.000105, loss: 0.6260 (2.0826)
2024-04-22 00:00:01,968 CLIP_COCO_TRAIN INFO: Epoch: 26, global_step: 6200, lr: 0.000100, loss: 0.5581 (2.0708)
2024-04-22 00:03:50,117 CLIP_COCO_TRAIN INFO: Epoch: 26, global_step: 6250, lr: 0.000095, loss: 0.6237 (2.0592)
2024-04-22 00:06:45,422 CLIP_COCO_TRAIN INFO: Epoch: 27, global_step: 6300, lr: 0.000091, loss: 0.5258 (2.0475)
2024-04-22 00:09:55,482 CLIP_COCO_TRAIN INFO: Epoch: 27, global_step: 6350, lr: 0.000086, loss: 0.5900 (2.0359)
2024-04-22 00:13:19,431 CLIP_COCO_TRAIN INFO: Epoch: 27, global_step: 6400, lr: 0.000082, loss: 0.5777 (2.0245)
2024-04-22 00:17:08,777 CLIP_COCO_TRAIN INFO: Epoch: 27, global_step: 6450, lr: 0.000077, loss: 0.5486 (2.0133)
2024-04-22 00:20:34,679 CLIP_COCO_TRAIN INFO: Epoch: 28, global_step: 6500, lr: 0.000073, loss: 0.5600 (2.0021)
2024-04-22 00:23:26,669 CLIP_COCO_TRAIN INFO: Epoch: 28, global_step: 6550, lr: 0.000069, loss: 0.4702 (1.9910)
2024-04-22 00:26:44,486 CLIP_COCO_TRAIN INFO: Epoch: 28, global_step: 6600, lr: 0.000065, loss: 0.5425 (1.9800)
2024-04-22 00:30:33,116 CLIP_COCO_TRAIN INFO: Epoch: 28, global_step: 6650, lr: 0.000061, loss: 0.5009 (1.9691)
2024-04-22 00:33:58,526 CLIP_COCO_TRAIN INFO: Epoch: 28, global_step: 6700, lr: 0.000057, loss: 0.5072 (1.9584)
2024-04-22 00:37:02,998 CLIP_COCO_TRAIN INFO: Epoch: 29, global_step: 6750, lr: 0.000053, loss: 0.5689 (1.9478)
2024-04-22 00:39:53,025 CLIP_COCO_TRAIN INFO: Epoch: 29, global_step: 6800, lr: 0.000049, loss: 0.5209 (1.9373)
2024-04-22 00:43:38,763 CLIP_COCO_TRAIN INFO: Epoch: 29, global_step: 6850, lr: 0.000046, loss: 0.4770 (1.9268)
2024-04-22 00:47:10,222 CLIP_COCO_TRAIN INFO: Epoch: 29, global_step: 6900, lr: 0.000042, loss: 0.5049 (1.9165)
2024-04-22 00:50:34,743 CLIP_COCO_TRAIN INFO: Epoch: 29, global_step: 6950, lr: 0.000039, loss: 0.5261 (1.9063)
2024-04-22 00:53:13,437 CLIP_COCO_TRAIN INFO: Epoch: 30, global_step: 7000, lr: 0.000036, loss: 0.4945 (1.8961)
2024-04-22 00:53:30,988 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_30_7000.pt
2024-04-22 00:57:02,382 CLIP_COCO_TRAIN INFO: Epoch: 30, global_step: 7050, lr: 0.000033, loss: 0.4805 (1.8860)
2024-04-22 01:00:30,205 CLIP_COCO_TRAIN INFO: Epoch: 30, global_step: 7100, lr: 0.000030, loss: 0.5123 (1.8761)
2024-04-22 01:03:56,276 CLIP_COCO_TRAIN INFO: Epoch: 30, global_step: 7150, lr: 0.000027, loss: 0.4566 (1.8663)
2024-04-22 01:07:18,630 CLIP_COCO_TRAIN INFO: Epoch: 31, global_step: 7200, lr: 0.000024, loss: 0.5293 (1.8565)
2024-04-22 01:10:22,354 CLIP_COCO_TRAIN INFO: Epoch: 31, global_step: 7250, lr: 0.000022, loss: 0.4747 (1.8468)
2024-04-22 01:13:38,220 CLIP_COCO_TRAIN INFO: Epoch: 31, global_step: 7300, lr: 0.000019, loss: 0.5506 (1.8373)
2024-04-22 01:17:04,274 CLIP_COCO_TRAIN INFO: Epoch: 31, global_step: 7350, lr: 0.000017, loss: 0.4028 (1.8278)
2024-04-22 01:20:31,376 CLIP_COCO_TRAIN INFO: Epoch: 31, global_step: 7400, lr: 0.000015, loss: 0.4114 (1.8185)
2024-04-22 01:23:53,087 CLIP_COCO_TRAIN INFO: Epoch: 32, global_step: 7450, lr: 0.000013, loss: 0.4112 (1.8093)
2024-04-22 01:26:53,435 CLIP_COCO_TRAIN INFO: Epoch: 32, global_step: 7500, lr: 0.000011, loss: 0.4148 (1.8001)
2024-04-22 01:30:15,464 CLIP_COCO_TRAIN INFO: Epoch: 32, global_step: 7550, lr: 0.000009, loss: 0.4481 (1.7910)
2024-04-22 01:33:43,590 CLIP_COCO_TRAIN INFO: Epoch: 32, global_step: 7600, lr: 0.000008, loss: 0.4725 (1.7821)
2024-04-22 01:37:23,081 CLIP_COCO_TRAIN INFO: Epoch: 32, global_step: 7650, lr: 0.000006, loss: 0.4497 (1.7733)
2024-04-22 01:40:06,907 CLIP_COCO_TRAIN INFO: Epoch: 33, global_step: 7700, lr: 0.000005, loss: 0.4097 (1.7645)
2024-04-22 01:43:18,577 CLIP_COCO_TRAIN INFO: Epoch: 33, global_step: 7750, lr: 0.000004, loss: 0.4127 (1.7559)
2024-04-22 01:46:47,180 CLIP_COCO_TRAIN INFO: Epoch: 33, global_step: 7800, lr: 0.000003, loss: 0.4749 (1.7475)
2024-04-22 01:50:37,125 CLIP_COCO_TRAIN INFO: Epoch: 33, global_step: 7850, lr: 0.000002, loss: 0.4021 (1.7390)
2024-04-22 01:53:47,698 CLIP_COCO_TRAIN INFO: Epoch: 34, global_step: 7900, lr: 0.000001, loss: 0.5132 (1.7308)
2024-04-22 01:56:33,720 CLIP_COCO_TRAIN INFO: Epoch: 34, global_step: 7950, lr: 0.000001, loss: 0.4719 (1.7226)
2024-04-22 01:59:57,038 CLIP_COCO_TRAIN INFO: Epoch: 34, global_step: 8000, lr: 0.000000, loss: 0.3293 (1.7145)
2024-04-22 02:00:16,692 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_34_8000.pt
2024-04-22 02:03:52,970 CLIP_COCO_TRAIN INFO: Epoch: 34, global_step: 8050, lr: 0.000000, loss: 0.4492 (1.7064)
2024-04-22 02:07:23,593 CLIP_COCO_TRAIN INFO: Epoch: 34, global_step: 8100, lr: 0.000000, loss: 0.4226 (1.6986)
2024-04-22 02:08:27,801 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_34_8120.pt
2024-04-22 02:08:28,220 CLIP_COCO_TRAIN INFO: Training done: total_step = 8120, avg loss = 1.6953722182145168
2024-04-22 21:09:03,568 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 8, 'num_workers': 8, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-04-22 21:17:52,242 CLIP_COCO_TRAIN INFO: ***** Running training *****
2024-04-22 21:17:52,243 CLIP_COCO_TRAIN INFO:   Num examples = 114955
2024-04-22 21:17:52,243 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2024-04-22 21:17:52,243 CLIP_COCO_TRAIN INFO:   Number of GPUs = 8
2024-04-22 21:17:52,244 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2024-04-22 21:17:52,244 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 512
2024-04-22 21:17:52,244 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2024-04-22 21:17:52,244 CLIP_COCO_TRAIN INFO:   Total optimization steps = 7875
2024-04-22 21:17:52,244 CLIP_COCO_TRAIN INFO:   warmup steps = 1575
2024-04-23 19:13:54,253 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 8, 'num_workers': 8, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-04-23 19:22:53,574 CLIP_COCO_TRAIN INFO: ***** Running training *****
2024-04-23 19:22:53,589 CLIP_COCO_TRAIN INFO:   Num examples = 114955
2024-04-23 19:22:53,590 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2024-04-23 19:22:53,590 CLIP_COCO_TRAIN INFO:   Number of GPUs = 8
2024-04-23 19:22:53,590 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2024-04-23 19:22:53,590 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 512
2024-04-23 19:22:53,590 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2024-04-23 19:22:53,590 CLIP_COCO_TRAIN INFO:   Total optimization steps = 7875
2024-04-23 19:22:53,590 CLIP_COCO_TRAIN INFO:   warmup steps = 1575
2024-04-23 19:34:41,600 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 8, 'num_workers': 8, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-04-23 19:41:43,366 CLIP_COCO_TRAIN INFO: ***** Running training *****
2024-04-23 19:41:43,366 CLIP_COCO_TRAIN INFO:   Num examples = 114955
2024-04-23 19:41:43,366 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2024-04-23 19:41:43,366 CLIP_COCO_TRAIN INFO:   Number of GPUs = 8
2024-04-23 19:41:43,367 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2024-04-23 19:41:43,367 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 512
2024-04-23 19:41:43,367 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2024-04-23 19:41:43,367 CLIP_COCO_TRAIN INFO:   Total optimization steps = 7875
2024-04-23 19:41:43,367 CLIP_COCO_TRAIN INFO:   warmup steps = 1575
2024-04-23 19:42:39,175 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 8, 'num_workers': 8, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-04-23 19:49:39,509 CLIP_COCO_TRAIN INFO: ***** Running training *****
2024-04-23 19:49:39,510 CLIP_COCO_TRAIN INFO:   Num examples = 114955
2024-04-23 19:49:39,511 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2024-04-23 19:49:39,511 CLIP_COCO_TRAIN INFO:   Number of GPUs = 8
2024-04-23 19:49:39,511 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2024-04-23 19:49:39,511 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 512
2024-04-23 19:49:39,511 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2024-04-23 19:49:39,511 CLIP_COCO_TRAIN INFO:   Total optimization steps = 7875
2024-04-23 19:49:39,511 CLIP_COCO_TRAIN INFO:   warmup steps = 1575
2024-04-24 15:44:26,153 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 8, 'num_workers': 8, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-04-24 16:16:09,176 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 8, 'num_workers': 8, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-04-24 16:25:03,979 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 8, 'num_workers': 8, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-04-24 16:26:04,358 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 8, 'num_workers': 8, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-04-24 16:30:15,617 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 8, 'num_workers': 8, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-04-24 16:36:39,132 CLIP_COCO_TRAIN INFO: ***** Running training *****
2024-04-24 16:36:39,152 CLIP_COCO_TRAIN INFO:   Num examples = 114358
2024-04-24 16:36:39,152 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2024-04-24 16:36:39,152 CLIP_COCO_TRAIN INFO:   Number of GPUs = 8
2024-04-24 16:36:39,152 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2024-04-24 16:36:39,153 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 512
2024-04-24 16:36:39,153 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2024-04-24 16:36:39,153 CLIP_COCO_TRAIN INFO:   Total optimization steps = 7840
2024-04-24 16:36:39,153 CLIP_COCO_TRAIN INFO:   warmup steps = 1568
2024-04-24 16:41:28,240 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 50, lr: 0.000016, loss: 6.0885 (6.2016)
2024-04-24 16:45:04,859 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 100, lr: 0.000032, loss: 5.6718 (6.0125)
2024-04-24 16:48:40,180 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 150, lr: 0.000048, loss: 5.1778 (5.8075)
2024-04-24 16:52:14,148 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 200, lr: 0.000064, loss: 4.9068 (5.6172)
2024-04-24 16:56:06,322 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 250, lr: 0.000080, loss: 4.6601 (5.4387)
2024-04-24 16:59:34,004 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 300, lr: 0.000096, loss: 4.5041 (5.2839)
2024-04-24 17:03:01,647 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 350, lr: 0.000112, loss: 4.2932 (5.1513)
2024-04-24 17:06:31,399 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 400, lr: 0.000128, loss: 4.1495 (5.0366)
2024-04-24 17:10:24,443 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 450, lr: 0.000143, loss: 3.9934 (4.9322)
2024-04-24 17:13:49,782 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 500, lr: 0.000159, loss: 3.7963 (4.8347)
2024-04-24 17:17:18,088 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 550, lr: 0.000175, loss: 3.8921 (4.7477)
2024-04-24 17:20:46,672 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 600, lr: 0.000191, loss: 3.7216 (4.6681)
2024-04-24 17:24:46,773 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 650, lr: 0.000207, loss: 3.6219 (4.5966)
2024-04-24 17:28:22,370 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 700, lr: 0.000223, loss: 3.4262 (4.5254)
2024-04-24 17:31:55,013 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 750, lr: 0.000239, loss: 3.4784 (4.4602)
2024-04-24 17:35:22,892 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 800, lr: 0.000255, loss: 3.4690 (4.3999)
2024-04-24 17:39:17,049 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 850, lr: 0.000271, loss: 3.5087 (4.3456)
2024-04-24 17:42:52,342 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 900, lr: 0.000287, loss: 3.2611 (4.2920)
2024-04-24 17:46:23,332 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 950, lr: 0.000303, loss: 3.3138 (4.2374)
2024-04-24 17:50:39,997 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 1000, lr: 0.000319, loss: 3.1016 (4.1871)
2024-04-24 17:50:55,511 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_4_1000.pt
2024-04-24 17:53:51,654 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 1050, lr: 0.000335, loss: 3.2918 (4.1416)
2024-04-24 17:57:31,445 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 1100, lr: 0.000351, loss: 3.1867 (4.0993)
2024-04-24 18:01:14,313 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 1150, lr: 0.000367, loss: 3.0638 (4.0546)
2024-04-24 18:04:49,811 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 1200, lr: 0.000383, loss: 3.0748 (4.0121)
2024-04-24 18:08:30,966 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 1250, lr: 0.000399, loss: 3.1884 (3.9730)
2024-04-24 18:11:59,143 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 1300, lr: 0.000415, loss: 2.9069 (3.9362)
2024-04-24 18:15:34,956 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 1350, lr: 0.000430, loss: 2.7985 (3.8993)
2024-04-24 18:19:04,226 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 1400, lr: 0.000446, loss: 2.8344 (3.8603)
2024-04-24 18:22:58,004 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 1450, lr: 0.000462, loss: 2.8342 (3.8253)
2024-04-24 18:26:25,522 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 1500, lr: 0.000478, loss: 2.8745 (3.7924)
2024-04-24 18:29:52,982 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 1550, lr: 0.000494, loss: 2.8107 (3.7608)
2024-04-24 18:33:24,548 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 1600, lr: 0.000500, loss: 2.6763 (3.7271)
2024-04-24 18:37:18,425 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 1650, lr: 0.000500, loss: 2.6703 (3.6947)
2024-04-24 18:40:48,756 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 1700, lr: 0.000499, loss: 2.5483 (3.6639)
2024-04-24 18:44:13,268 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 1750, lr: 0.000499, loss: 2.5595 (3.6346)
2024-04-24 18:47:39,906 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 1800, lr: 0.000498, loss: 2.3968 (3.6056)
2024-04-24 18:51:31,361 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 1850, lr: 0.000498, loss: 2.4365 (3.5732)
2024-04-24 18:54:56,823 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 1900, lr: 0.000497, loss: 2.4288 (3.5431)
2024-04-24 18:58:26,515 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 1950, lr: 0.000495, loss: 2.5341 (3.5149)
2024-04-24 19:02:00,442 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 2000, lr: 0.000494, loss: 2.4027 (3.4880)
2024-04-24 19:02:45,597 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_8_2000.pt
2024-04-24 19:06:00,493 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 2050, lr: 0.000493, loss: 2.1432 (3.4582)
2024-04-24 19:09:25,338 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 2100, lr: 0.000491, loss: 2.3111 (3.4294)
2024-04-24 19:12:57,363 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 2150, lr: 0.000489, loss: 2.2044 (3.4016)
2024-04-24 19:16:21,444 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 2200, lr: 0.000488, loss: 2.2724 (3.3758)
2024-04-24 19:20:16,531 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 2250, lr: 0.000486, loss: 1.9541 (3.3497)
2024-04-24 19:23:45,591 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 2300, lr: 0.000483, loss: 2.0309 (3.3212)
2024-04-24 19:27:15,106 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 2350, lr: 0.000481, loss: 2.2221 (3.2952)
2024-04-24 19:30:42,824 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 2400, lr: 0.000479, loss: 2.1468 (3.2702)
2024-04-24 19:34:38,026 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 2450, lr: 0.000476, loss: 2.0998 (3.2467)
2024-04-24 19:38:05,843 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 2500, lr: 0.000473, loss: 1.9784 (3.2206)
2024-04-24 19:41:33,077 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 2550, lr: 0.000470, loss: 1.9195 (3.1952)
2024-04-24 19:44:59,585 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 2600, lr: 0.000467, loss: 2.0478 (3.1710)
2024-04-24 19:48:56,224 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 2650, lr: 0.000464, loss: 1.8663 (3.1477)
2024-04-24 19:52:27,516 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 2700, lr: 0.000461, loss: 1.7376 (3.1244)
2024-04-24 19:55:56,634 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 2750, lr: 0.000457, loss: 1.7103 (3.0998)
2024-04-24 19:59:24,160 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 2800, lr: 0.000454, loss: 1.8820 (3.0765)
2024-04-24 20:03:16,205 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 2850, lr: 0.000450, loss: 1.7793 (3.0542)
2024-04-24 20:06:49,521 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 2900, lr: 0.000446, loss: 1.9604 (3.0330)
2024-04-24 20:10:23,138 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 2950, lr: 0.000442, loss: 1.7090 (3.0098)
2024-04-24 20:13:51,747 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 3000, lr: 0.000438, loss: 1.7163 (2.9869)
2024-04-24 20:14:13,487 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_13_3000.pt
2024-04-24 20:17:44,359 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 3050, lr: 0.000434, loss: 1.6474 (2.9653)
2024-04-24 20:21:16,697 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 3100, lr: 0.000430, loss: 1.8376 (2.9450)
2024-04-24 20:24:43,183 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 3150, lr: 0.000426, loss: 1.4502 (2.9244)
2024-04-24 20:28:12,919 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 3200, lr: 0.000421, loss: 1.4549 (2.9022)
2024-04-24 20:32:09,278 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 3250, lr: 0.000416, loss: 1.4203 (2.8810)
2024-04-24 20:35:36,405 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 3300, lr: 0.000412, loss: 1.6243 (2.8609)
2024-04-24 20:39:07,005 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 3350, lr: 0.000407, loss: 1.7488 (2.8416)
2024-04-24 20:42:37,722 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 3400, lr: 0.000402, loss: 1.3336 (2.8209)
2024-04-24 20:46:34,015 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 3450, lr: 0.000397, loss: 1.3005 (2.8005)
2024-04-24 20:50:00,151 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 3500, lr: 0.000392, loss: 1.5100 (2.7812)
2024-04-24 20:53:30,118 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 3550, lr: 0.000387, loss: 1.5731 (2.7627)
2024-04-24 20:56:57,619 CLIP_COCO_TRAIN INFO: Epoch: 16, global_step: 3600, lr: 0.000381, loss: 1.2099 (2.7437)
2024-04-24 21:01:01,835 CLIP_COCO_TRAIN INFO: Epoch: 16, global_step: 3650, lr: 0.000376, loss: 1.3253 (2.7239)
2024-04-24 21:04:27,812 CLIP_COCO_TRAIN INFO: Epoch: 16, global_step: 3700, lr: 0.000370, loss: 1.4214 (2.7049)
2024-04-24 21:07:54,471 CLIP_COCO_TRAIN INFO: Epoch: 16, global_step: 3750, lr: 0.000365, loss: 1.3305 (2.6867)
2024-04-24 21:11:22,472 CLIP_COCO_TRAIN INFO: Epoch: 16, global_step: 3800, lr: 0.000359, loss: 1.3662 (2.6693)
2024-04-24 21:15:16,329 CLIP_COCO_TRAIN INFO: Epoch: 17, global_step: 3850, lr: 0.000354, loss: 1.1590 (2.6503)
2024-04-24 21:18:44,450 CLIP_COCO_TRAIN INFO: Epoch: 17, global_step: 3900, lr: 0.000348, loss: 1.3106 (2.6320)
2024-04-24 21:22:14,243 CLIP_COCO_TRAIN INFO: Epoch: 17, global_step: 3950, lr: 0.000342, loss: 1.2806 (2.6141)
2024-04-24 21:25:37,603 CLIP_COCO_TRAIN INFO: Epoch: 17, global_step: 4000, lr: 0.000336, loss: 1.2367 (2.5969)
2024-04-24 21:26:19,960 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_17_4000.pt
2024-04-24 21:29:43,578 CLIP_COCO_TRAIN INFO: Epoch: 18, global_step: 4050, lr: 0.000330, loss: 1.0714 (2.5793)
2024-04-24 21:33:08,829 CLIP_COCO_TRAIN INFO: Epoch: 18, global_step: 4100, lr: 0.000324, loss: 1.0072 (2.5613)
2024-04-24 21:36:38,438 CLIP_COCO_TRAIN INFO: Epoch: 18, global_step: 4150, lr: 0.000318, loss: 1.1601 (2.5438)
2024-04-24 21:40:14,754 CLIP_COCO_TRAIN INFO: Epoch: 18, global_step: 4200, lr: 0.000312, loss: 1.1357 (2.5274)
2024-04-24 21:43:57,226 CLIP_COCO_TRAIN INFO: Epoch: 18, global_step: 4250, lr: 0.000306, loss: 1.2134 (2.5111)
2024-04-24 21:47:33,141 CLIP_COCO_TRAIN INFO: Epoch: 19, global_step: 4300, lr: 0.000300, loss: 1.0531 (2.4941)
2024-04-24 21:51:01,996 CLIP_COCO_TRAIN INFO: Epoch: 19, global_step: 4350, lr: 0.000294, loss: 0.9919 (2.4771)
2024-04-24 21:54:32,068 CLIP_COCO_TRAIN INFO: Epoch: 19, global_step: 4400, lr: 0.000288, loss: 1.0876 (2.4608)
2024-04-24 21:58:21,661 CLIP_COCO_TRAIN INFO: Epoch: 19, global_step: 4450, lr: 0.000282, loss: 1.0504 (2.4450)
2024-04-24 22:01:59,036 CLIP_COCO_TRAIN INFO: Epoch: 20, global_step: 4500, lr: 0.000276, loss: 0.9998 (2.4290)
2024-04-24 22:05:25,404 CLIP_COCO_TRAIN INFO: Epoch: 20, global_step: 4550, lr: 0.000269, loss: 0.9557 (2.4126)
2024-04-24 22:08:57,716 CLIP_COCO_TRAIN INFO: Epoch: 20, global_step: 4600, lr: 0.000263, loss: 0.9825 (2.3967)
2024-04-24 22:12:42,842 CLIP_COCO_TRAIN INFO: Epoch: 20, global_step: 4650, lr: 0.000257, loss: 1.0321 (2.3813)
2024-04-24 22:16:15,616 CLIP_COCO_TRAIN INFO: Epoch: 20, global_step: 4700, lr: 0.000251, loss: 0.9522 (2.3663)
2024-04-24 22:19:54,423 CLIP_COCO_TRAIN INFO: Epoch: 21, global_step: 4750, lr: 0.000244, loss: 0.8662 (2.3506)
2024-04-24 22:23:24,590 CLIP_COCO_TRAIN INFO: Epoch: 21, global_step: 4800, lr: 0.000238, loss: 0.8809 (2.3353)
2024-04-24 22:27:22,046 CLIP_COCO_TRAIN INFO: Epoch: 21, global_step: 4850, lr: 0.000232, loss: 0.9735 (2.3203)
2024-04-24 22:30:51,450 CLIP_COCO_TRAIN INFO: Epoch: 21, global_step: 4900, lr: 0.000225, loss: 0.9635 (2.3057)
2024-04-24 22:34:23,126 CLIP_COCO_TRAIN INFO: Epoch: 22, global_step: 4950, lr: 0.000219, loss: 0.8237 (2.2910)
2024-04-24 22:37:38,230 CLIP_COCO_TRAIN INFO: Epoch: 22, global_step: 5000, lr: 0.000213, loss: 0.8194 (2.2762)
2024-04-24 22:37:41,581 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_22_5000.pt
2024-04-24 22:41:23,911 CLIP_COCO_TRAIN INFO: Epoch: 22, global_step: 5050, lr: 0.000207, loss: 0.7101 (2.2615)
2024-04-24 22:44:28,836 CLIP_COCO_TRAIN INFO: Epoch: 22, global_step: 5100, lr: 0.000201, loss: 0.7464 (2.2475)
2024-04-24 22:47:43,312 CLIP_COCO_TRAIN INFO: Epoch: 22, global_step: 5150, lr: 0.000195, loss: 0.8213 (2.2337)
2024-04-24 22:51:24,323 CLIP_COCO_TRAIN INFO: Epoch: 23, global_step: 5200, lr: 0.000189, loss: 0.6952 (2.2194)
2024-04-24 22:55:19,900 CLIP_COCO_TRAIN INFO: Epoch: 23, global_step: 5250, lr: 0.000182, loss: 0.7074 (2.2054)
2024-04-24 22:58:49,101 CLIP_COCO_TRAIN INFO: Epoch: 23, global_step: 5300, lr: 0.000176, loss: 0.7574 (2.1918)
2024-04-24 23:02:18,135 CLIP_COCO_TRAIN INFO: Epoch: 23, global_step: 5350, lr: 0.000171, loss: 0.7425 (2.1783)
2024-04-24 23:05:49,227 CLIP_COCO_TRAIN INFO: Epoch: 24, global_step: 5400, lr: 0.000165, loss: 0.5717 (2.1647)
2024-04-24 23:09:43,363 CLIP_COCO_TRAIN INFO: Epoch: 24, global_step: 5450, lr: 0.000159, loss: 0.7266 (2.1511)
2024-04-24 23:13:06,707 CLIP_COCO_TRAIN INFO: Epoch: 24, global_step: 5500, lr: 0.000153, loss: 0.6582 (2.1378)
2024-04-24 23:16:42,906 CLIP_COCO_TRAIN INFO: Epoch: 24, global_step: 5550, lr: 0.000147, loss: 0.7719 (2.1248)
2024-04-24 23:19:58,727 CLIP_COCO_TRAIN INFO: Epoch: 24, global_step: 5600, lr: 0.000142, loss: 0.2751 (2.1119)
2024-04-24 23:24:02,607 CLIP_COCO_TRAIN INFO: Epoch: 25, global_step: 5650, lr: 0.000136, loss: 0.5364 (2.0988)
2024-04-24 23:27:30,682 CLIP_COCO_TRAIN INFO: Epoch: 25, global_step: 5700, lr: 0.000130, loss: 0.6854 (2.0858)
2024-04-24 23:31:01,044 CLIP_COCO_TRAIN INFO: Epoch: 25, global_step: 5750, lr: 0.000125, loss: 0.6972 (2.0731)
2024-04-24 23:34:31,067 CLIP_COCO_TRAIN INFO: Epoch: 25, global_step: 5800, lr: 0.000120, loss: 0.6307 (2.0606)
2024-04-24 23:38:26,398 CLIP_COCO_TRAIN INFO: Epoch: 26, global_step: 5850, lr: 0.000114, loss: 0.6372 (2.0482)
2024-04-24 23:41:56,490 CLIP_COCO_TRAIN INFO: Epoch: 26, global_step: 5900, lr: 0.000109, loss: 0.5647 (2.0358)
2024-04-24 23:45:26,675 CLIP_COCO_TRAIN INFO: Epoch: 26, global_step: 5950, lr: 0.000104, loss: 0.6152 (2.0236)
2024-04-24 23:48:57,902 CLIP_COCO_TRAIN INFO: Epoch: 26, global_step: 6000, lr: 0.000099, loss: 0.5653 (2.0115)
2024-04-24 23:49:22,411 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_26_6000.pt
2024-04-24 23:52:54,579 CLIP_COCO_TRAIN INFO: Epoch: 27, global_step: 6050, lr: 0.000094, loss: 0.5616 (1.9997)
2024-04-24 23:56:21,993 CLIP_COCO_TRAIN INFO: Epoch: 27, global_step: 6100, lr: 0.000089, loss: 0.5053 (1.9876)
2024-04-24 23:59:44,943 CLIP_COCO_TRAIN INFO: Epoch: 27, global_step: 6150, lr: 0.000084, loss: 0.5396 (1.9758)
2024-04-25 00:03:14,796 CLIP_COCO_TRAIN INFO: Epoch: 27, global_step: 6200, lr: 0.000080, loss: 0.6174 (1.9641)
2024-04-25 00:07:08,714 CLIP_COCO_TRAIN INFO: Epoch: 27, global_step: 6250, lr: 0.000075, loss: 0.5792 (1.9527)
2024-04-25 00:10:45,313 CLIP_COCO_TRAIN INFO: Epoch: 28, global_step: 6300, lr: 0.000071, loss: 0.5230 (1.9412)
2024-04-25 00:14:05,541 CLIP_COCO_TRAIN INFO: Epoch: 28, global_step: 6350, lr: 0.000066, loss: 0.5003 (1.9298)
2024-04-25 00:17:41,032 CLIP_COCO_TRAIN INFO: Epoch: 28, global_step: 6400, lr: 0.000062, loss: 0.5037 (1.9185)
2024-04-25 00:21:32,668 CLIP_COCO_TRAIN INFO: Epoch: 28, global_step: 6450, lr: 0.000058, loss: 0.5259 (1.9075)
2024-04-25 00:25:01,860 CLIP_COCO_TRAIN INFO: Epoch: 29, global_step: 6500, lr: 0.000054, loss: 0.4003 (1.8966)
2024-04-25 00:28:31,568 CLIP_COCO_TRAIN INFO: Epoch: 29, global_step: 6550, lr: 0.000050, loss: 0.4910 (1.8857)
2024-04-25 00:32:04,893 CLIP_COCO_TRAIN INFO: Epoch: 29, global_step: 6600, lr: 0.000047, loss: 0.4333 (1.8750)
2024-04-25 00:35:59,678 CLIP_COCO_TRAIN INFO: Epoch: 29, global_step: 6650, lr: 0.000043, loss: 0.4203 (1.8644)
2024-04-25 00:39:30,395 CLIP_COCO_TRAIN INFO: Epoch: 29, global_step: 6700, lr: 0.000040, loss: 0.4564 (1.8539)
2024-04-25 00:42:52,264 CLIP_COCO_TRAIN INFO: Epoch: 30, global_step: 6750, lr: 0.000036, loss: 0.4383 (1.8434)
2024-04-25 00:46:19,199 CLIP_COCO_TRAIN INFO: Epoch: 30, global_step: 6800, lr: 0.000033, loss: 0.4775 (1.8331)
2024-04-25 00:50:06,261 CLIP_COCO_TRAIN INFO: Epoch: 30, global_step: 6850, lr: 0.000030, loss: 0.4582 (1.8228)
2024-04-25 00:53:30,946 CLIP_COCO_TRAIN INFO: Epoch: 30, global_step: 6900, lr: 0.000027, loss: 0.3393 (1.8128)
2024-04-25 00:57:04,817 CLIP_COCO_TRAIN INFO: Epoch: 31, global_step: 6950, lr: 0.000024, loss: 0.4067 (1.8028)
2024-04-25 01:00:31,165 CLIP_COCO_TRAIN INFO: Epoch: 31, global_step: 7000, lr: 0.000022, loss: 0.4466 (1.7929)
2024-04-25 01:00:44,272 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_31_7000.pt
2024-04-25 01:04:31,424 CLIP_COCO_TRAIN INFO: Epoch: 31, global_step: 7050, lr: 0.000019, loss: 0.5372 (1.7831)
2024-04-25 01:07:59,884 CLIP_COCO_TRAIN INFO: Epoch: 31, global_step: 7100, lr: 0.000017, loss: 0.5027 (1.7735)
2024-04-25 01:11:30,293 CLIP_COCO_TRAIN INFO: Epoch: 31, global_step: 7150, lr: 0.000015, loss: 0.3788 (1.7640)
2024-04-25 01:15:03,448 CLIP_COCO_TRAIN INFO: Epoch: 32, global_step: 7200, lr: 0.000013, loss: 0.4087 (1.7545)
2024-04-25 01:18:59,782 CLIP_COCO_TRAIN INFO: Epoch: 32, global_step: 7250, lr: 0.000011, loss: 0.3341 (1.7451)
2024-04-25 01:22:32,087 CLIP_COCO_TRAIN INFO: Epoch: 32, global_step: 7300, lr: 0.000009, loss: 0.4249 (1.7359)
2024-04-25 01:26:05,178 CLIP_COCO_TRAIN INFO: Epoch: 32, global_step: 7350, lr: 0.000007, loss: 0.4019 (1.7269)
2024-04-25 01:29:40,002 CLIP_COCO_TRAIN INFO: Epoch: 33, global_step: 7400, lr: 0.000006, loss: 0.3673 (1.7179)
2024-04-25 01:33:22,878 CLIP_COCO_TRAIN INFO: Epoch: 33, global_step: 7450, lr: 0.000005, loss: 0.3490 (1.7090)
2024-04-25 01:36:49,717 CLIP_COCO_TRAIN INFO: Epoch: 33, global_step: 7500, lr: 0.000004, loss: 0.4126 (1.7001)
2024-04-25 01:40:19,617 CLIP_COCO_TRAIN INFO: Epoch: 33, global_step: 7550, lr: 0.000003, loss: 0.3882 (1.6915)
2024-04-25 01:43:49,917 CLIP_COCO_TRAIN INFO: Epoch: 33, global_step: 7600, lr: 0.000002, loss: 0.3606 (1.6829)
2024-04-25 01:47:48,518 CLIP_COCO_TRAIN INFO: Epoch: 34, global_step: 7650, lr: 0.000001, loss: 0.3991 (1.6745)
2024-04-25 01:51:12,549 CLIP_COCO_TRAIN INFO: Epoch: 34, global_step: 7700, lr: 0.000001, loss: 0.4030 (1.6661)
2024-04-25 01:54:44,003 CLIP_COCO_TRAIN INFO: Epoch: 34, global_step: 7750, lr: 0.000000, loss: 0.3869 (1.6579)
2024-04-25 01:58:16,550 CLIP_COCO_TRAIN INFO: Epoch: 34, global_step: 7800, lr: 0.000000, loss: 0.4096 (1.6498)
2024-04-25 02:01:06,901 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints/checkpoint_34_7840.pt
2024-04-25 02:01:07,535 CLIP_COCO_TRAIN INFO: Training done: total_step = 7840, avg loss = 1.6433494519974505
2024-04-25 13:44:44,502 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 8, 'num_workers': 8, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-04-26 17:33:36,377 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 8, 'num_workers': 8, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-04-26 17:36:19,990 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 8, 'num_workers': 8, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-04-26 17:42:24,316 CLIP_COCO_TRAIN INFO: ***** Running training *****
2024-04-26 17:42:24,349 CLIP_COCO_TRAIN INFO:   Num examples = 114358
2024-04-26 17:42:24,350 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2024-04-26 17:42:24,350 CLIP_COCO_TRAIN INFO:   Number of GPUs = 8
2024-04-26 17:42:24,350 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2024-04-26 17:42:24,350 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 512
2024-04-26 17:42:24,350 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2024-04-26 17:42:24,351 CLIP_COCO_TRAIN INFO:   Total optimization steps = 7840
2024-04-26 17:42:24,351 CLIP_COCO_TRAIN INFO:   warmup steps = 1568
2024-04-26 17:47:18,310 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 50, lr: 0.000016, loss: 6.0885 (6.2016)
2024-04-26 17:50:49,042 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 100, lr: 0.000032, loss: 5.6718 (6.0125)
2024-06-29 18:47:29,509 CLIP_CC3M_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 128, 'per_gpu_eval_batch_size': 128, 'n_gpu': 4, 'num_workers': 32, 'num_train_epochs': 50, 'gradient_accumulation_steps': 4, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-06-29 18:48:38,622 CLIP_CC3M_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 128, 'per_gpu_eval_batch_size': 128, 'n_gpu': 4, 'num_workers': 32, 'num_train_epochs': 50, 'gradient_accumulation_steps': 4, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-06-29 18:49:49,770 CLIP_CC3M_TRAIN INFO: ***** Running training *****
2024-06-29 18:49:49,771 CLIP_CC3M_TRAIN INFO:   Num examples = 2889855
2024-06-29 18:49:49,771 CLIP_CC3M_TRAIN INFO:   Num Epochs = 50
2024-06-29 18:49:49,771 CLIP_CC3M_TRAIN INFO:   Number of GPUs = 4
2024-06-29 18:49:49,771 CLIP_CC3M_TRAIN INFO:   Batch size per GPU = 128
2024-06-29 18:49:49,771 CLIP_CC3M_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 2048
2024-06-29 18:49:49,771 CLIP_CC3M_TRAIN INFO:   Gradient Accumulation steps = 4
2024-06-29 18:49:49,771 CLIP_CC3M_TRAIN INFO:   Total optimization steps = 70550
2024-06-29 18:49:49,771 CLIP_CC3M_TRAIN INFO:   warmup steps = 14110
2024-06-29 19:03:00,535 CLIP_CC3M_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 128, 'per_gpu_eval_batch_size': 128, 'n_gpu': 4, 'num_workers': 32, 'num_train_epochs': 50, 'gradient_accumulation_steps': 4, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-06-29 19:04:26,475 CLIP_CC3M_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 128, 'per_gpu_eval_batch_size': 128, 'n_gpu': 4, 'num_workers': 32, 'num_train_epochs': 50, 'gradient_accumulation_steps': 4, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-06-29 19:05:31,596 CLIP_CC3M_TRAIN INFO: ***** Running training *****
2024-06-29 19:05:31,596 CLIP_CC3M_TRAIN INFO:   Num examples = 2905954
2024-06-29 19:05:31,596 CLIP_CC3M_TRAIN INFO:   Num Epochs = 50
2024-06-29 19:05:31,596 CLIP_CC3M_TRAIN INFO:   Number of GPUs = 4
2024-06-29 19:05:31,596 CLIP_CC3M_TRAIN INFO:   Batch size per GPU = 128
2024-06-29 19:05:31,597 CLIP_CC3M_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 2048
2024-06-29 19:05:31,597 CLIP_CC3M_TRAIN INFO:   Gradient Accumulation steps = 4
2024-06-29 19:05:31,597 CLIP_CC3M_TRAIN INFO:   Total optimization steps = 70950
2024-06-29 19:05:31,597 CLIP_CC3M_TRAIN INFO:   warmup steps = 14190
2024-06-29 19:07:05,279 CLIP_CC3M_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 128, 'per_gpu_eval_batch_size': 128, 'n_gpu': 4, 'num_workers': 32, 'num_train_epochs': 50, 'gradient_accumulation_steps': 4, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-06-29 19:08:00,741 CLIP_CC3M_TRAIN INFO: ***** Running training *****
2024-06-29 19:08:00,742 CLIP_CC3M_TRAIN INFO:   Num examples = 2905954
2024-06-29 19:08:00,742 CLIP_CC3M_TRAIN INFO:   Num Epochs = 50
2024-06-29 19:08:00,742 CLIP_CC3M_TRAIN INFO:   Number of GPUs = 4
2024-06-29 19:08:00,742 CLIP_CC3M_TRAIN INFO:   Batch size per GPU = 128
2024-06-29 19:08:00,742 CLIP_CC3M_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 2048
2024-06-29 19:08:00,742 CLIP_CC3M_TRAIN INFO:   Gradient Accumulation steps = 4
2024-06-29 19:08:00,742 CLIP_CC3M_TRAIN INFO:   Total optimization steps = 70950
2024-06-29 19:08:00,742 CLIP_CC3M_TRAIN INFO:   warmup steps = 14190
2024-06-29 19:13:42,574 CLIP_CC3M_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 128, 'per_gpu_eval_batch_size': 128, 'n_gpu': 4, 'num_workers': 32, 'num_train_epochs': 50, 'gradient_accumulation_steps': 4, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2024-06-29 19:14:37,939 CLIP_CC3M_TRAIN INFO: ***** Running training *****
2024-06-29 19:14:37,939 CLIP_CC3M_TRAIN INFO:   Num examples = 2905954
2024-06-29 19:14:37,939 CLIP_CC3M_TRAIN INFO:   Num Epochs = 50
2024-06-29 19:14:37,939 CLIP_CC3M_TRAIN INFO:   Number of GPUs = 4
2024-06-29 19:14:37,939 CLIP_CC3M_TRAIN INFO:   Batch size per GPU = 128
2024-06-29 19:14:37,939 CLIP_CC3M_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 2048
2024-06-29 19:14:37,940 CLIP_CC3M_TRAIN INFO:   Gradient Accumulation steps = 4
2024-06-29 19:14:37,940 CLIP_CC3M_TRAIN INFO:   Total optimization steps = 70950
2024-06-29 19:14:37,940 CLIP_CC3M_TRAIN INFO:   warmup steps = 14190
